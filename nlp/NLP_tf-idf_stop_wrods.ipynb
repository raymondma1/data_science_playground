{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop words, tf-idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "try:\n",
    "    df = pd.read_csv('../data/nlp_data/rt_critics.csv')\n",
    "except IOError:\n",
    "    print 'cannot find file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh    imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709        Time Out   \n",
       "1     Richard Corliss  fresh  114709   TIME Magazine   \n",
       "2         David Ansen  fresh  114709        Newsweek   \n",
       "3       Leonard Klady  fresh  114709         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709  Chicago Reader   \n",
       "\n",
       "                                               quote review_date  rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So ingenious in concept, design and execution that you could watch it on a postage stamp-sized screen and still be engulfed by its charm.',\n",
       " \"The year's most inventive comedy.\",\n",
       " 'A winning animated feature that has something for everyone on the age spectrum.',\n",
       " \"The film sports a provocative and appealing story that's every bit the equal of this technical achievement.\",\n",
       " \"An entertaining computer-generated, hyperrealist animation feature (1995) that's also in effect a toy catalog.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "documents = list(df['quote'])\n",
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize  # for tokenizing our text\n",
    "import string  # helps with removing punctuation\n",
    "from collections import Counter  # great dict-like datastructure for counting things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a few tokens: [['so', 'ingenious', 'in', 'concept', 'design', 'and', 'execution', 'that', 'you', 'could', 'watch', 'it', 'on', 'a', 'postage', 'stamp', 'sized', 'screen', 'and', 'still', 'be', 'engulfed', 'by', 'its', 'charm'], ['the', 'years', 'most', 'inventive', 'comedy'], ['a', 'winning', 'animated', 'feature', 'that', 'has', 'something', 'for', 'everyone', 'on', 'the', 'age', 'spectrum']]\n",
      "number of tokens: 280092\n",
      "number of unique tokens: 22424\n",
      "number of documents: 14072\n"
     ]
    }
   ],
   "source": [
    "# This is a bit of text cleanup\n",
    "word_bag_list = []\n",
    "for doc in documents:\n",
    "    cleaned = doc.lower().replace('-', ' ')  # make lowercase and split hyphenated words in two\n",
    "    for c in string.punctuation:  # strip punctuation marks.\n",
    "        cleaned = cleaned.replace(c, '')\n",
    "    word_bag_list.append(wordpunct_tokenize(cleaned))\n",
    "\n",
    "print 'a few tokens:', word_bag_list[:3]\n",
    "\n",
    "# this flattens the nested lists into one big list for some stats\n",
    "token_list = []\n",
    "for tokens in word_bag_list:\n",
    "    token_list.extend(tokens)\n",
    "print 'number of tokens:', len(token_list)\n",
    "print 'number of unique tokens:', len(set(token_list))\n",
    "print 'number of documents:', len(word_bag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so',\n",
       " 'ingenious',\n",
       " 'in',\n",
       " 'concept',\n",
       " 'design',\n",
       " 'and',\n",
       " 'execution',\n",
       " 'that',\n",
       " 'you',\n",
       " 'could',\n",
       " 'watch',\n",
       " 'it',\n",
       " 'on',\n",
       " 'a',\n",
       " 'postage',\n",
       " 'stamp',\n",
       " 'sized',\n",
       " 'screen',\n",
       " 'and',\n",
       " 'still',\n",
       " 'be',\n",
       " 'engulfed',\n",
       " 'by',\n",
       " 'its',\n",
       " 'charm']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_bag_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'and',\n",
       " 'be',\n",
       " 'by',\n",
       " 'charm',\n",
       " 'concept',\n",
       " 'could',\n",
       " 'design',\n",
       " 'engulfed',\n",
       " 'execution',\n",
       " 'in',\n",
       " 'ingenious',\n",
       " 'it',\n",
       " 'its',\n",
       " 'on',\n",
       " 'postage',\n",
       " 'screen',\n",
       " 'sized',\n",
       " 'so',\n",
       " 'stamp',\n",
       " 'still',\n",
       " 'that',\n",
       " 'watch',\n",
       " 'you'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = word_bag_list[0]\n",
    "set(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'one', 'two'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['one','one','two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.6140562819783968),\n",
       " ('a', 0.5035531552018192),\n",
       " ('and', 0.48969584991472426),\n",
       " ('of', 0.4640420693575895),\n",
       " ('is', 0.3320068220579875),\n",
       " ('to', 0.32106310403638433),\n",
       " ('in', 0.23848777714610575),\n",
       " ('that', 0.20082433200682206),\n",
       " ('its', 0.1991898806139852),\n",
       " ('it', 0.1960631040363843),\n",
       " ('with', 0.15513075611142696),\n",
       " ('but', 0.15157760090960773),\n",
       " ('this', 0.1467453098351336),\n",
       " ('movie', 0.12933484934621944),\n",
       " ('film', 0.12926378624218307),\n",
       " ('for', 0.1286242183058556),\n",
       " ('as', 0.12784252416145536),\n",
       " ('an', 0.10993462194428652),\n",
       " ('be', 0.08484934621944286),\n",
       " ('on', 0.08449403069926094)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the document frequency of all the unique tokens in the bags of words.\n",
    "\n",
    "df = Counter() \n",
    "\n",
    "for doc in word_bag_list:\n",
    "    for token in set(doc):\n",
    "        df[token] += 1\n",
    "\n",
    "for token in df:\n",
    "    df[token] = df[token] / float(len(documents))\n",
    "\n",
    "# this prints the 20 highest-scoring words and their scores\n",
    "df.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tf.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print len(tf)\n",
    "# print len(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Mann and a superlative cast have taken a classic heist movie rife with familiar genre elements and turned it into a sleek, accomplished piece of work, meticulously controlled and completely involving.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00412166003411029"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['michael']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('engulfed', 0.38207769145669573), ('postage', 0.35435180423429802), ('sized', 0.32662591701190019), ('stamp', 0.30424128549448326), ('ingenious', 0.26874915769444713)]\n",
      "[('inventive', 1.1776761280575496), ('years', 0.8588893828779226), ('comedy', 0.65543605303509112), ('most', 0.59453821488145864), ('the', 0.097533738115198984)]\n",
      "[('spectrum', 0.65025615367302192), ('winning', 0.47574203511007074), ('everyone', 0.43231666566869759), ('age', 0.39485397527852278), ('animated', 0.39393272981339084)]\n",
      "[('equal', 0.39185708991301349), ('sports', 0.37253332126759958), ('provocative', 0.34790330157005933), ('technical', 0.34201603930200153), ('achievement', 0.34201603930200153)]\n",
      "[('catalog', 0.63679615242782617), ('hyperrealist', 0.63679615242782617), ('1995', 0.49031451393874498), ('toy', 0.45195690427850749), ('generated', 0.41464918508281268)]\n",
      "[('ushered', 0.23879855716043485), ('revived', 0.23879855716043485), ('lion', 0.19400457042973349), ('repetition', 0.19400457042973349), ('landmark', 0.19015080343405202)]\n",
      "[('conceptual', 0.35377564023768121), ('wholl', 0.31308629621293643), ('verbal', 0.28741417841441996), ('defined', 0.27239695218819165), ('appreciated', 0.27239695218819165)]\n",
      "[('anthropomorphism', 0.36738239563143821), ('toys', 0.28287375804158366), ('will', 0.28198755807440296), ('marvel', 0.2607443678529851), ('irresistible', 0.25413474258657515)]\n",
      "[('foray', 0.30812717052959332), ('invested', 0.26340799759024208), ('cleverness', 0.24104841112056638), ('imagery', 0.20698219582220143), ('generated', 0.20063670245942547)]\n",
      "[('toys', 0.3343053504127807), ('speak', 0.31422204349100619), ('tim', 0.2957918113042714), ('hanks', 0.28972220254861131), ('guys', 0.2827153534655541)]\n",
      "[('coaster', 0.63518117535962337), ('roller', 0.63518117535962337), ('visionary', 0.61630486947069207), ('ride', 0.51455654439152432), ('result', 0.47831662229718214)]\n",
      "[('wondrously', 0.38884037739511923), ('holiday', 0.31464301463099781), ('generated', 0.29617798934486617), ('imaginative', 0.28981935160084127), ('town', 0.28981935160084127)]\n",
      "[('popper', 0.70444416647910701), ('d', 0.53470400587402034), ('3', 0.50718386530147219), ('disneys', 0.49508536448109741), ('eye', 0.4635798533210933)]\n",
      "[('docter', 0.30812717052959332), ('pete', 0.30812717052959332), ('ranft', 0.30812717052959332), ('throats', 0.2857675840599177), ('lasseter', 0.2857675840599177)]\n",
      "[('overcommercialization', 0.95519422864173942), ('negative', 0.84533299977492848), ('involves', 0.73547177090811755), ('toy', 0.67793535641776126), ('disneys', 0.59410243737731694)]\n",
      "[('technically', 1.1521474928003559), ('toy', 1.1298922606962687), ('flawless', 1.0768166388431797), ('nearly', 0.87921269456688977), ('story', 0.53005507319758949)]\n",
      "[('playthings', 0.34114079594347829), ('eager', 0.27714938632819064), ('andy', 0.26266848961004197), ('draw', 0.26266848961004197), ('20th', 0.25550167905782223)]\n",
      "[('miraculous', 0.24862735287497895), ('i', 0.20943986701820069), ('toy', 0.19939275188757682), ('imagine', 0.17900607010640196), ('produced', 0.17637041838023471)]\n",
      "[('changer', 0.63679615242782617), ('puns', 0.56355533318328566), ('added', 0.45195690427850749), ('voice', 0.4123097637620613), ('game', 0.35549563874941914)]\n",
      "[('gloomy', 0.61096187492179188), ('generating', 0.57480774959519676), ('grotesque', 0.56574751608316731), ('extravaganza', 0.56574751608316731), ('despair', 0.53746099453506591)]\n",
      "[('extravaganza', 0.91933971363514688), ('calculated', 0.86411061960026692), ('special', 0.56683280620030874), ('effects', 0.53745860729634554), ('entertaining', 0.51587403361699891)]\n",
      "[('matthau', 0.68144577737364997), ('walter', 0.5850793951816986), ('lemmon', 0.57480774959519676), ('awfully', 0.53176038129247194), ('jack', 0.48715895858070718)]\n",
      "[('regrettably', 3.8800914085946694), ('mediocre', 3.2781050064317014)]\n",
      "[('bickering', 0.46962944431940468), ('neil', 0.43112126762162989), ('simon', 0.40859542828228745), ('disappointed', 0.39261309092385521), ('expect', 0.31559673752830575)]\n",
      "[('1993', 0.26227697025386487), ('list', 0.20677911120441311), ('10', 0.20304760828578441), ('wont', 0.18936204399555087), ('among', 0.18877258077626463)]\n",
      "[('ariels', 0.31839807621391308), ('grumps', 0.31839807621391308), ('dictated', 0.29529317019524831), ('practiced', 0.29529317019524831), ('progress', 0.25353440457873599)]\n",
      "[('grumpys', 0.73476479126287642), ('poke', 0.65025615367302192), ('somewhere', 0.49029911200534226), ('cheap', 0.48715895858070718), ('worthy', 0.46816972181674366)]\n",
      "[('melrose', 0.56187895802455257), ('escapes', 0.48033223089985316), ('aura', 0.43955886733750338), ('queasy', 0.43263045347536322), ('problems', 0.36586692801424647)]\n",
      "[('rigorous', 0.34023533022072933), ('examination', 0.30644657121171559), ('undemanding', 0.30644657121171559), ('diverting', 0.27756543868838457), ('sit', 0.26067105918387767)]\n",
      "[('flaring', 0.39799759526739137), ('rejoice', 0.39799759526739137), ('lollygags', 0.39799759526739137), ('stomp', 0.39799759526739137), ('sputtering', 0.34023533022072933)]\n",
      "[('mcmillans', 0.73476479126287642), ('celebratory', 0.73476479126287642), ('sister', 0.62812676348442342), ('terry', 0.61096187492179188), ('selling', 0.51682530325855214)]\n",
      "[('crippling', 0.26844833654113487), ('bashing', 0.26844833654113487), ('exhale', 0.25616151508331164), ('crack', 0.24068195072676649), ('psyche', 0.2351570550663436)]\n",
      "[('mishandles', 0.73476479126287642), ('whitaker', 0.65025615367302192), ('clumsily', 0.59693713978379537), ('tour', 0.52148873570597021), ('girl', 0.44910540151639128)]\n",
      "[('grappling', 0.35377564023768121), ('exhale', 0.31308629621293643), ('waiting', 0.24101554995162852), ('issues', 0.22906097986781182), ('uneven', 0.21362046861107897)]\n",
      "[('bernadine', 0.39799759526739137), ('populating', 0.39799759526739137), ('exception', 0.30205654972597284), ('capture', 0.29445981819289141), ('sympathy', 0.27756543868838457)]\n",
      "[('men', 0.36008337559524572), ('musing', 0.3293773202212894), ('wardrobe', 0.30547569330542929), ('her', 0.28836581091653324), ('i', 0.24555018891789049)]\n",
      "[('fraker', 0.29849819645054354), ('equilibriums', 0.29849819645054354), ('rattled', 0.26416656242966513), ('retro', 0.23768850429256502), ('fluff', 0.23768850429256502)]\n",
      "[('crook', 0.23879855716043485), ('somebodys', 0.23879855716043485), ('jobs', 0.22146987764643625), ('bruised', 0.22146987764643625), ('stare', 0.20414119813243761)]\n",
      "[('warring', 0.28945279655810285), ('taciturn', 0.28945279655810285), ('braying', 0.28945279655810285), ('ashley', 0.25616151508331164), ('val', 0.2474438765241668)]\n",
      "[('robberies', 0.36738239563143821), ('tautly', 0.34072288868682499), ('elaborately', 0.2925396975908493), ('satisfaction', 0.28287375804158366), ('edited', 0.26873049726753295)]\n",
      "[('reinvests', 0.27291263675478267), ('postmodernist', 0.24152371422140811), ('modernist', 0.24152371422140811), ('artifice', 0.23330422643707155), ('lay', 0.21731520392463088)]\n",
      "[('proportion', 0.25136690227414193), ('nowadays', 0.23312618699624865), ('lengthy', 0.21488547171835537), ('robbers', 0.20901327299956035), ('1995', 0.19354520287055724)]\n",
      "[('asphalt', 0.34114079594347829), ('interpersonal', 0.34114079594347829), ('discussions', 0.31638553949490889), ('fitted', 0.31638553949490889), ('robbers', 0.28366087049940331)]\n",
      "[('invited', 0.35222208323955351), ('fortunately', 0.31135419769739825), ('mann', 0.29445981819289141), ('exceptional', 0.28803687320008897), ('party', 0.27317541720264177)]\n",
      "[('forges', 0.63277107898981777), ('180', 0.58326056609267884), ('heat', 0.46481570347814072), ('mark', 0.44956041059970803), ('consistently', 0.4347290274012619)]\n",
      "[('occupies', 0.76848454524993492), ('exalted', 0.74233162957250043), ('position', 0.72204585218029949), ('countless', 0.70547116519903086), ('heat', 0.5915836226085428)]\n",
      "[('niros', 0.59693713978379537), ('devoted', 0.56574751608316731), ('parody', 0.49357292849909573), ('robert', 0.41981520955348417), ('himself', 0.40163145739469719)]\n",
      "[('indeed', 0.32082240352441227), ('decade', 0.32082240352441227), ('finest', 0.29071363340670131), ('crime', 0.27814791199265598), ('period', 0.27287988620976472)]\n",
      "[('beside', 0.35502817066510889), ('expose', 0.33739925292127559), ('weaknesses', 0.33069704945052525), ('pale', 0.32489133672771991), ('mouse', 0.32489133672771991)]\n",
      "[('superlative', 0.24820326168697793), ('rife', 0.23351564827304869), ('meticulously', 0.22983492840878672), ('controlled', 0.22654241229447963), ('mann', 0.22084486364466857)]\n"
     ]
    }
   ],
   "source": [
    "# calculate the term frequency of all the unique tokens in all of the bags of words.\n",
    "\n",
    "for doc in word_bag_list[:50]:\n",
    "    tf = Counter() \n",
    "    tfidf = Counter()\n",
    "    \n",
    "\n",
    "    # calculate term frequencies\n",
    "    for token in doc:\n",
    "        tf[token] += 1\n",
    "    total = float(sum(tf.values()))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # calculate tf-idf scores\n",
    "    for token in tf:\n",
    "        tfidf[token] = (tf[token] / total) * (-np.log(df[token]))\n",
    "\n",
    "    # this prints most significant words in the document\n",
    "    print tfidf.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21254"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words='english')\n",
    "output = tfidf_vec.fit_transform(documents)\n",
    "# print output.toarray()[20:30, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print tfidf_vec.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
